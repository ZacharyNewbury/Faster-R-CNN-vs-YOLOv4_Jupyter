{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dataset convert.ipynb","provenance":[],"authorship_tag":"ABX9TyOVOM6Ad3amK8b/0/09RrGa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YBx1JE4tl-P0"},"source":["This program is used to convert the LISA Dataset CSV format to other custom dataset formats:  \n","* Detectron2 for Faster R-CNN  \n","* Darknet for <span style=\"color:red\">YOLOv4</span>\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xm6zUAAHr9lV","cellView":"form","executionInfo":{"status":"ok","timestamp":1619050104624,"user_tz":240,"elapsed":21513,"user":{"displayName":"Zachary Newbury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0VbxxJFu_Z5puzJUENjYPLaVS1KvMwrrxh_XsSQ=s64","userId":"08338740760284225846"}},"outputId":"0340ea0c-b5f3-4024-8b70-3d95287b78f7"},"source":["#@title connect to drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"77uVyl4EoeeZ"},"source":["#@title specify paths for conversion\n","#@markdown path to LISA directory\n","LISA_path = \"/content/drive/MyDrive/thesis/LISA dataset/\" #@param {type:\"string\"}\n","#@markdown path where Detectron2 directory will be made\n","COCO_path = \"/content/drive/MyDrive/thesis/COCO\" #@param {type:\"string\"}\n","#@markdown path where Darknet directory will be made\n","YOLO_path = \"/content/drive/MyDrive/thesis/YOLO/dataset\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3tooIWW7oo8D"},"source":["#@title import common python libraries\n","import numpy as np\n","import os, json, cv2, random, time, ntpath, csv\n","from shutil import copyfile\n","from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AD7eFxGN9Fke","executionInfo":{"status":"ok","timestamp":1618950362239,"user_tz":240,"elapsed":280,"user":{"displayName":"Zachary Newbury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0VbxxJFu_Z5puzJUENjYPLaVS1KvMwrrxh_XsSQ=s64","userId":"08338740760284225846"}},"outputId":"4cb8950f-a6d5-4443-e0bd-4bc65fa4af05"},"source":["#@title specify class names\n","class_names =(\n","\"\"\"pedestrianCrossing\n","signalAhead\n","speedLimit35\n","speedLimit25\n","keepRight\n","addedLane\n","merge\n","yield\n","laneEnds\n","stopAhead\n","speedLimit45\n","speedLimit30\n","school\"\"\")\n","print(class_names)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["pedestrianCrossing\n","signalAhead\n","speedLimit35\n","speedLimit25\n","keepRight\n","addedLane\n","merge\n","yield\n","laneEnds\n","stopAhead\n","speedLimit45\n","speedLimit30\n","school\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IjiR5e1jnwRb"},"source":["#Detectron2 Custom dataset format\n","Detectron2 dataset format explained in the detectron2 manual found [here](https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html)  \n","Note: the bbox_mode is set to 0 but should be BoxMode.XYXY_ABS. This is because when saved to JSON it will be converted to 0 anyways and can't be loaded as a detectron2 object. Instead the bbox_mode should be set to the correct mode when loaded from file.  \n"]},{"cell_type":"code","metadata":{"id":"_05mmBrS9TtO"},"source":["#@title create switch function for getting name index, if -1 error\n","#get unique category id for each sign type\n","#returns negative if not valid\n","#these are the classes with 200 or more instances\n","def get_category_num(category):\n","    text=class_names\n","    switcher={}\n","    i=0\n","    for field in text.split(\"\\n\"):\n","      switcher[field]=i\n","      i=i+1;\n","    #print switcher to confirm that it is formatted correctly\n","\n","    return switcher.get(category, -1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0yI8LvKsl5FA"},"source":["# this code was made to generate dict file to let trainer know the metadata for each image and annotations for each\n","\n","#function to format dict for training images\n","def get_sign_dicts(img_dir):\n","    \n","    #all files stored in annotation file\n","    csv_file = os.path.join(img_dir, \"allAnnotations.csv\")\n","\n","    with open(csv_file, newline='') as f:\n","      reader = csv.DictReader(f, dialect='excel', delimiter=';')\n","      dataset_dicts=[]\n","      picc=0 #picture counter\n","      for row in reader:\n","          category_id = get_category_num(row['Annotation tag'])\n","          # category id must be valid to add to dict\n","          if category_id != -1:\n","              record = {}\n","              \n","              filename = os.path.join(img_dir, row[\"Filename\"])\n","              height, width = cv2.imread(filename).shape[:2]\n","\n","              record[\"file_name\"] = filename\n","              record[\"image_id\"] = row[\"Filename\"] # all images have unique filename\n","              record[\"height\"] = height\n","              record[\"width\"] = width\n","\n","              #generate annotations\n","              obj = {\n","                  \"bbox\": [int(row[\"x1\"]), int(row[\"y1\"]), int(row[\"x2\"]), int(row[\"y2\"])],\n","                  \"bbox_mode\": 0, #should be BoxMode.XYXY_ABS but will be set on load instead\n","                  \"category_id\": category_id\n","              }\n","              record[\"annotations\"] = [obj]\n","\n","              #logging\n","              print(picc, record[\"image_id\"])\n","              picc+=1 #1 more picture counted\n","\n","              dataset_dicts.append(record)\n","              \n","      return dataset_dicts\n","\n","#create dict\n","data = get_sign_dicts(LISA_path)\n","\n","#w+ option for open forces file to be made if dne\n","#write to file the full data in COCO format\n","with open(os.path.join(LISA_path, \"COCO_Annotations_Full.json\"), \"w+\") as outfile:\n","    json.dump(data, outfile)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fk9ojZyOqK5N"},"source":["# seperate into different subsets: train, test and valid"]},{"cell_type":"code","metadata":{"id":"afUzXxopqViv"},"source":["#@title create json file for Test, Train and Valid sets from Full json\n","\n","#load data from json\n","with open(os.path.join(LISA_path, \"COCO_Annotations_Full.json\"), \"r\") as outfile:\n","    data = json.load(outfile)\n","\n","#shuffle data\n","random.shuffle(data)\n","\n","#split data into test and train\n","test_ratio = 10 #10% test data\n","test_bp = len(data) // 10\n","test = data[:test_bp ]\n","interm_data = data[ test_bp:] #intermediate data to create train and valid set\n","\n","# do a k partition of train data\n","k = 4\n","valid_bp = len(interm_data) // k\n","valid = interm_data[:valid_bp]\n","train = interm_data[valid_bp:]\n","\n","#write results to files\n","#w+ option for open forces file to be made if dne\n","#write to file the full data in COCO format\n","with open(os.path.join(LISA_path, \"COCO_Annotations_Train.json\"), \"w+\") as outfile:\n","    json.dump(train, outfile)\n","\n","with open(os.path.join(LISA_path, \"COCO_Annotations_Valid.json\"), \"w+\") as outfile:\n","    json.dump(valid, outfile)\n","\n","with open(os.path.join(LISA_path, \"COCO_Annotations_Test.json\"), \"w+\") as outfile:\n","    json.dump(test, outfile)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QvclQxLHpn_Q"},"source":["#Darknet Custom dataset format\n","Darknet dataset format explained in AlexeyAB github https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects  \n","This will copy files to new dataset directory and rename them for each partition [train, valid, test]  \n","Uses files generated for detectron2 dataset format"]},{"cell_type":"code","metadata":{"id":"lAvQP2i9qHQl"},"source":["#@title create yolo dataset from LISA in darknet format\n","\n","print_time(\"opening files\")\n","\n","with open(os.path.join(LISA_path, \"COCO_Annotations_Test.json\"), \"r\") as outfile:\n","    test = json.load(outfile)\n","    outfile.close()\n","\n","with open(os.path.join(LISA_path, \"COCO_Annotations_Valid.json\"), \"r\") as outfile:\n","    valid = json.load(outfile)\n","    outfile.close()\n","\n","with open(os.path.join(LISA_path, \"COCO_Annotations_Train.json\"), \"r\") as outfile:\n","    train = json.load(outfile)\n","    outfile.close()\n","\n","#use train and test to create YOLO format dataset\n","\n","print_time(\"creating class.names file\")\n","\n","#class names for yolov4 format\n","names = open( os.path.join(YOLO_path,\"class.names\"), \"w+\" )\n","names.write(class_names)\n","names.close()\n","\n","print_time(\"creating dataset folders\")\n","#make directories for test and train pictures\n","train_dir  = os.path.join(YOLO_path, \"train\")\n","valid_dir  = os.path.join(YOLO_path, \"valid\")\n","test_dir   = os.path.join(YOLO_path, \"test\")\n","backup_dir = os.path.join(YOLO_path, \"backup\")\n","\n","for x in [train_dir, valid_dir, test_dir, backup_dir]:\n","  os.mkdirs(x,exist_ok=True)\n","\n","print_time(\"finished creating dataset folders\")\n","\n","## this function generates a darknet format of the dataset\n","## this uses a pytorch-yolov4 format so i made a second function to fix it\n","#ipath - initial path\n","#dpath - destination path\n","#data  - coco data generated for faster RCNN\n","#sel   - selection, train or test\n","def generate_files_darknet(ipath, dpath, data, sel):\n","    for row in data:\n","        category_id = row[\"annotations\"][0][\"category_id\"]\n","\n","        img_path = row[\"file_name\"] #gives relative path to file\n","        \n","        #calculate width/height and centers\n","        x1 = row[\"annotations\"][0][\"bbox\"][0]\n","        y1 = row[\"annotations\"][0][\"bbox\"][1]\n","        x2 = row[\"annotations\"][0][\"bbox\"][2]\n","        y2 = row[\"annotations\"][0][\"bbox\"][3]\n","        img_width  = row[\"width\"]\n","        img_height = row[\"height\"]\n","\n","        center_x = (x2+x1) / (2 * img_width)\n","        center_y = (y2+y1) / (2 * img_height)\n","        width  = (x2-x1) / img_width\n","        height = (y2-y1) / img_height\n","\n","        #get the file name from the path\n","        filename_ext = ntpath.basename(img_path)\n","        filename     = os.path.splitext(filename_ext)[0]\n","        \n","        #create the text file from the file name\n","        text_path = os.path.join(dpath, sel, filename+\".txt\")\n","\n","        temp   = [category_id, center_x, center_y, width, height]\n","        output = ' '.join(map(str, temp))\n","        print(output)\n","        text_file = open(text_path, \"w+\")\n","        text_file.write(output)\n","        text_file.close()\n","\n","        #copy image to path\n","        start_path = os.path.join(ipath, img_path)           #src path to pict\n","        dest_path  = os.path.join(dpath, sel, filename_ext)  #dest path of pict\n","        copyfile(start_path, dest_path)                      #copy file to dest\n","\n","\n","   \n","print_time(\"copying pictures and creating txt files in new folders\")\n","#copy pictures and data to new folders\n","generate_files_darknet(LISA_path, YOLO_path, train, \"train\")\n","generate_files_darknet(LISA_path, YOLO_path, valid, \"valid\")\n","generate_files_darknet(LISA_path, YOLO_path, test, \"test\")\n","print_time(\"finished copying and generating files\")\n","\n","print_time(\"creating txt files for image paths\")\n","#create test and train text files\n","!ls \"$test_dir/\"*.png  >  \"$yolo_path\\test.txt\"\n","!ls \"$valid_dir/\"*.png  >  \"$yolo_path\\valid.txt\"\n","!ls \"$train_dir/\"*.png >  \"$yolo_path\\train.txt\"\n","print_time(\"finished creating txt files\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FosMDBak4IQN","executionInfo":{"status":"ok","timestamp":1619055645206,"user_tz":240,"elapsed":3770,"user":{"displayName":"Zachary Newbury","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0VbxxJFu_Z5puzJUENjYPLaVS1KvMwrrxh_XsSQ=s64","userId":"08338740760284225846"}},"outputId":"b2cbc13b-79cf-4f58-95a0-d177097dcb34"},"source":["import cv2, os, json\n","from google.colab.patches import cv2_imshow\n","\n","YOLO_path = \"/content/drive/MyDrive/thesis/YOLO/dataset\"\n","filename = os.path.join(YOLO_path, 'valid', f+'.png')\n","\n","flist = ['pedestrian_1323896918.avi_image17',\n","         'addedLane_1331865841.avi_image2',\n","         'speedLimit25_1333396150.avi_image3',\n","         'speedLimit35_1333397516.avi_image3',\n","         'speedLimit30_1333395349.avi_image13',\n","         'speedLimit45_1333393955.avi_image5',\n","         'pedestrianCrossing_1333395980.avi_image5',\n","         'laneEnds_1333394350.avi_image10',\n","         'merge_1331866392.avi_image22',\n","         'keepRight_1323823831.avi_image3',\n","         'stopAhead_1323819280.avi_image9',\n","         'school_1330547188.avi_image3',\n","         'yield_1323802820.avi_image0'\n","         ]\n","\n","LISA_path = \"/content/drive/MyDrive/thesis/LISA dataset/\"\n","with open(os.path.join(LISA_path, \"COCO_Annotations_Full.json\"), \"r\") as outfile:\n","    data = json.load(outfile)\n","\n","for row in data:\n","  for f in flist:\n","    if f in row[\"file_name\"]:\n","      imgdata = row\n","      #calculate width/height and centers\n","      x1 = imgdata[\"annotations\"][0][\"bbox\"][0]\n","      y1 = imgdata[\"annotations\"][0][\"bbox\"][1]\n","      x2 = imgdata[\"annotations\"][0][\"bbox\"][2]\n","      y2 = imgdata[\"annotations\"][0][\"bbox\"][3]\n","\n","      image = cv2.imread(imgdata[\"file_name\"])\n","      cv2.imwrite(\"/content/drive/MyDrive/thesis/signimages/\"+f.split('_')[0]+'.png' ,  image[y1:y2, x1:x2,:])\n","      print(f.split('_')[0])   \n","\n"],"execution_count":70,"outputs":[{"output_type":"stream","text":["school\n","addedLane\n","merge\n","speedLimit45\n","laneEnds\n","laneEnds\n","speedLimit30\n","pedestrianCrossing\n","pedestrianCrossing\n","speedLimit25\n","speedLimit35\n","yield\n","stopAhead\n","keepRight\n","pedestrian\n"],"name":"stdout"}]}]}